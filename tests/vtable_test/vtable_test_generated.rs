// automatically generated by the FlatBuffers compiler, do not modify


pub mod vtable_test {
    #![allow(unused_imports, irrefutable_let_patterns, dead_code, unused_mut)]
    use flatbuffers::{
        deserialize::{FromStructField, FromTableField, FromTableFieldUnion, Str, Table, Vector},
        errors::{InvalidFlatbuffer, OutOfBufferSpace, TryFromEnumError},
        serialize::{
            builder::FlatbufferWriter, FlatbufferPrimitive, FlatbufferTable, Offset, RawOffset,
        },
    };
    use core::{
        convert::{TryFrom, TryInto},
        fmt, ptr,
    };

    /// View of a flatbuffer `VtableTester` object
    ///
    /// This struct is used for deserializing. For serializing see [`VtableTester`](struct.VtableTester.html).
    ///
    /// an example documentation comment: monster object
    #[derive(Copy, Clone)]
    pub struct VtableTesterView<'a> {
        table: Table<'a>,
    }

    #[doc(hidden)]
    impl<'a> FromTableField<'a> for VtableTesterView<'a> {
        const INLINE_SIZE: usize = Table::INLINE_SIZE;

        #[inline]
        fn from_field(buf: &'a [u8], offset: usize) -> Result<Self, InvalidFlatbuffer> {
            FromTableField::from_field(buf, offset).map(|table| Self { table })
        }
    }

    impl<'a> VtableTesterView<'a> {
        /// Getter for the `bit1` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit1(&self) -> u8 {
            self.try_get_bit1().unwrap()
        }

        /// Getter for the `bit1` field.
        ///
        #[inline]
        pub fn try_get_bit1(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(4).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit2` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit2(&self) -> u8 {
            self.try_get_bit2().unwrap()
        }

        /// Getter for the `bit2` field.
        ///
        #[inline]
        pub fn try_get_bit2(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(6).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit4` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit4(&self) -> u8 {
            self.try_get_bit4().unwrap()
        }

        /// Getter for the `bit4` field.
        ///
        #[inline]
        pub fn try_get_bit4(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(8).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit8` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit8(&self) -> u8 {
            self.try_get_bit8().unwrap()
        }

        /// Getter for the `bit8` field.
        ///
        #[inline]
        pub fn try_get_bit8(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(10).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit16` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit16(&self) -> u8 {
            self.try_get_bit16().unwrap()
        }

        /// Getter for the `bit16` field.
        ///
        #[inline]
        pub fn try_get_bit16(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(12).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit32` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit32(&self) -> u8 {
            self.try_get_bit32().unwrap()
        }

        /// Getter for the `bit32` field.
        ///
        #[inline]
        pub fn try_get_bit32(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(14).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit64` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit64(&self) -> u8 {
            self.try_get_bit64().unwrap()
        }

        /// Getter for the `bit64` field.
        ///
        #[inline]
        pub fn try_get_bit64(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(16).map(|value| value.unwrap_or(0))
        }

        /// Getter for the `bit128` field.
        ///
        ///
        /// # Panics
        ///
        /// If the value cannot be deserialized.
        #[inline]
        pub fn bit128(&self) -> u8 {
            self.try_get_bit128().unwrap()
        }

        /// Getter for the `bit128` field.
        ///
        #[inline]
        pub fn try_get_bit128(&self) -> Result<u8, InvalidFlatbuffer> {
            self.table.get_field(18).map(|value| value.unwrap_or(0))
        }

        /// Begin parsing a flatbuffer with a `Weapon` as the root object
        #[inline]
        pub fn from_buffer_as_root(buffer: &'a [u8]) -> Result<Self, InvalidFlatbuffer> {
            FromTableField::from_field(buffer, 0)
        }
    }

    #[inline]
    pub fn get_root_as_vtable_tester<'a>(buffer: &'a [u8]) -> Result<VtableTesterView<'a>, InvalidFlatbuffer> {
        VtableTesterView::from_buffer_as_root(buffer)
    }

    impl<'a> fmt::Debug for VtableTesterView<'a> {
        fn fmt(&self, formatter: &mut fmt::Formatter<'_>) -> fmt::Result {
            formatter.debug_struct("VtableTesterView")
                .field("bit1", &self.try_get_bit1())
                .field("bit2", &self.try_get_bit2())
                .field("bit4", &self.try_get_bit4())
                .field("bit8", &self.try_get_bit8())
                .field("bit16", &self.try_get_bit16())
                .field("bit32", &self.try_get_bit32())
                .field("bit64", &self.try_get_bit64())
                .field("bit128", &self.try_get_bit128())
                .finish()
        }
    }

    /// Builder for a flatbuffer `VtableTester` object
    ///
    /// This struct is used for serializing. For deserializing see [`VtableTesterView`](struct.VtableTesterView.html).
    ///
    /// an example documentation comment: monster object
    #[derive(Copy, Clone, Debug, PartialEq)]
    pub struct VtableTester {
        pub bit1: u8,
        pub bit2: u8,
        pub bit4: u8,
        pub bit8: u8,
        pub bit16: u8,
        pub bit32: u8,
        pub bit64: u8,
        pub bit128: u8,
    }

    impl Default for VtableTester {
        #[inline]
        fn default() -> VtableTester {
            VtableTester {
                bit1: 0,
                bit2: 0,
                bit4: 0,
                bit8: 0,
                bit16: 0,
                bit32: 0,
                bit64: 0,
                bit128: 0,
            }
        }
    }

    unsafe impl FlatbufferTable for VtableTester {
        #[inline]
        fn validate_required(&self) {
        }

        #[inline]
        fn serialize<F: FlatbufferWriter>(
            &self,
            flatbuffer: &mut F,
        ) -> Result<RawOffset, OutOfBufferSpace> {
            let mut vtable = [0u8; 20];

            let mut size = 0;
            let mut alignment = 4;
            let mut vtable_len = 4;

            if self.bit1 != 0 {
                vtable_len = vtable_len.max(4 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[4..4+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit2 != 0 {
                vtable_len = vtable_len.max(6 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[6..6+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit4 != 0 {
                vtable_len = vtable_len.max(8 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[8..8+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit8 != 0 {
                vtable_len = vtable_len.max(10 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[10..10+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit16 != 0 {
                vtable_len = vtable_len.max(12 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[12..12+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit32 != 0 {
                vtable_len = vtable_len.max(14 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[14..14+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit64 != 0 {
                vtable_len = vtable_len.max(16 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[16..16+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            if self.bit128 != 0 {
                vtable_len = vtable_len.max(18 + 2);
                const CUR_ALIGN: usize = <u8 as FlatbufferPrimitive>::ALIGNMENT;
                alignment = alignment.max(CUR_ALIGN);
                vtable[18..18+2].copy_from_slice(
                    &((size + 4) as u16).to_le_bytes());
                size += <u8 as FlatbufferPrimitive>::SIZE;
            }
            flatbuffer.align_before_write(size, alignment - 1)?;
            if self.bit128 != 0 {
                flatbuffer.write_primitive(&self.bit128)?;
            }
            if self.bit64 != 0 {
                flatbuffer.write_primitive(&self.bit64)?;
            }
            if self.bit32 != 0 {
                flatbuffer.write_primitive(&self.bit32)?;
            }
            if self.bit16 != 0 {
                flatbuffer.write_primitive(&self.bit16)?;
            }
            if self.bit8 != 0 {
                flatbuffer.write_primitive(&self.bit8)?;
            }
            if self.bit4 != 0 {
                flatbuffer.write_primitive(&self.bit4)?;
            }
            if self.bit2 != 0 {
                flatbuffer.write_primitive(&self.bit2)?;
            }
            if self.bit1 != 0 {
                flatbuffer.write_primitive(&self.bit1)?;
            }
            flatbuffer.write_vtable_and_offset(&mut vtable[..vtable_len], size + 4)
        }
    }
}
